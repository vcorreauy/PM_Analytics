# -*- coding: utf-8 -*-
"""Jira-Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h3seQJd46EXt1QkM076ETHVTHc3Ryb9v

#Objetivos


*   Extraer informacion de Jira
*   Procesar y crear Dataframes
*   Crear Dashboard estado actual proyectos
*   Crear un modelo predictivo para todas las variables del modelo

#Alcance

Abarca todos los proyectos creados en Jira dentro de una organizacion

#Premisas


1.   Comenzaremos trabajando solo con las finalizadas
2.   En segunda etapa se incorporaran el resto de las incidencias

#Estructura

El trabajo se ordena según los siguientes capitulos

#Obtención de Datos

##Using JIRA library for Python.
"""

#Instalamos la librería Jira
!pip install jira

"""###Carga de Librerias"""

# import the installed Jira library
from jira import JIRA
from jira.resources import User
import re
from datetime import datetime
from dateutil import parser
from dateutil.parser import parse
import pytz
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.decomposition import PCA

"""###Validamos credenciales para acceder a Jira"""

# Specify a server key. It should be your
# domain name link. yourdomainname.atlassian.net
jiraOptions = {'server': "https://XXX.atlassian.net"}

# Get a JIRA client instance, pass,
# Authentication parameters
# and the Server name.
# emailID = your emailID
# token = token you receive after registration
jira = JIRA(options=jiraOptions, basic_auth=("XXX@XXX.com", "XXX"))

"""**Estamos listos para analizar los datos!**

---

##Visión General
"""

# Visión holística de los Proyectos
projects = jira.projects()
# print(projects)
print("Cantidad de Proyectos:",len(projects)) # nro de proyectos en Jira

# Obtengo lista de proyectos
for proyecto in projects:
  print(proyecto.name)

"""##Definir consulta JQL para los issues que nos interesan

Lo importante aquí es la consistencia en la consulta, es decir, filtrar issues/proyectos con la misma estructura
"""

# Definimos la consulta JQL para obtener los issues que nos interesan
jql = 'project = "OIA" and status="Listo"' # (uno en particular) #'projectType = "software"'#'project = "OIA"' #'project != null' (todos)#
issues = jira.search_issues(jql, maxResults=None)

print("Cantidad de Issues:",len(issues))
#print(issues)

"""**Definimos las variables que nos interesan analizar**

##***Campos de las indicencias***

*   identificador-> issue.key
*   responsable->issue.fields.assignee.displayName
*   story_points->issue.fields.storypoints (!!)
*   prioridad-> ->issue.fields.priority
*   tipo_incidencia->issue.fields.issuetype
*   proyecto-> issue.fields.project
*   estado-> issue.fields.status
*   roles-> jira.project_roles()
*   tiempo_resolucion-> (issue.fields.resolutiondate - issue.fields.created).days , esto para service management, para soft creamos campo fecha y hora de resolucion
*   Presupuesto (costo) -> customfield_10055

Ver:
Bloqueando
Bloqueantes
HAY QUE HACER CONSULTA JQL issuelinktype in ('is blocked by') o Blocking


*A tener en cuenta:*

Para los campos personalizados, hay que mirar el html y buscar los customfield_XXXX

Describir el problema de story points: Revisando en foros, documentacion y html, no he logrado capturar el valor del campo story points, por lo que se puede utilizar otro campo que capture ese valor. En este caso, se creó el campo "horas estimadas de trabajo"

Pasamos a revisar entonces cada una de estas variables

###Identificador Incidencia
"""

incidencias_key=[]
for i in issues:
    key_issue=i.key
    incidencias_key.append(key_issue)

print(len(incidencias_key))
print(incidencias_key)

"""###Responsables"""

#Obtén el usuario asignado para cada uno
asignados=[]
for issue in issues:
    # Verifica si el issue tiene un asignado
    if issue.fields.assignee is not None:
        # Accede al atributo displayName del objeto User del atributo assignee
        assignee_name = issue.fields.assignee.displayName
        asignados.append(assignee_name)
    else:
        assignee_name='Sin Asignar'
        asignados.append(assignee_name)

print(len(asignados))
print(asignados)

"""###Story Points"""

points=[] # customfield_10051 es "Horas estimadas de trabajo", replica el valor de story points con una automatizacion
for i in issues:

    if i.fields.customfield_10051 is not None:
        punto = i.fields.customfield_10051
        points.append(punto)
    else:
        punto=0
        points.append(punto)

print(len(points))
print(points)

"""###Prioridad"""

incidencias_prioridad=[]
for i in issues:
    prioridad=i.fields.priority.name
    incidencias_prioridad.append(prioridad)

print(len(incidencias_prioridad))
print(incidencias_prioridad)

"""###Tipo de Incidencia"""

incidencias_tipo=[]
for i in issues:
    tipo=i.fields.issuetype.name
    incidencias_tipo.append(tipo)

print(len(incidencias_tipo))
print(incidencias_tipo)

"""###Proyecto"""

incidencias_proyecto=[]
for i in issues:
    proyecto=i.fields.project.name
    incidencias_proyecto.append(proyecto)

print(len(incidencias_proyecto))
print(incidencias_proyecto)

"""###Estado de las Incidencias"""

incidencias_estado=[]
for i in issues:
    estado=i.fields.status.name
    incidencias_estado.append(estado)

print(len(incidencias_estado))
print(incidencias_estado)

"""###Presupuesto"""

presupuesto=[]
for i in issues:
    valor=i.fields.customfield_10055
    presupuesto.append(valor)

print(len(presupuesto))
print(presupuesto)

"""###Tiempo de Creación, Cierre y Tiempo de Trabajo"""

#Fecha y hora de Creacion
incidencias_tiempo_resol=[]
for i in issues:
    fecha_hora_jira=i.fields.created
    # Parsear la cadena de texto a un objeto datetime
    dt = parser.parse(fecha_hora_jira)
    # Obtener la fecha, hora y minutos
    fecha_hora_minutos = dt.strftime('%d-%m-%Y %H:%M') #%d-%m-%Y%H:%M
    incidencias_tiempo_resol.append(fecha_hora_minutos)

print(len(incidencias_tiempo_resol))
print(incidencias_tiempo_resol)

#Fecha y hora de Cierre   -> Fecha y Hora de resolucion (customfield_10077)
incidencias_tiempo_cierre=[]
for i in issues:
    if i.fields.customfield_10077 is not None:
      momento_cierre=i.fields.customfield_10077
      # Parsear la cadena de texto a un objeto datetime
      dt_2 = parser.parse(momento_cierre)
      # Obtener la fecha, hora y minutos
      fecha_hora_minutos = dt_2.strftime('%d-%m-%Y %H:%M') #%d-%m-%Y%H:%M
      incidencias_tiempo_cierre.append(fecha_hora_minutos)
    else:
      momento_cierre="0"
      incidencias_tiempo_cierre.append(momento_cierre)

print(len(incidencias_tiempo_cierre))
print(incidencias_tiempo_cierre)

# Aquellas incidencias con valor 0 indican que estan abiertas
# En este caso trabajamos solamente con incidencias cerradas

#Calculamos los dias laborables
dias_lab=[]

for issue in issues:
    # Obtén las fechas de inicio y finalización directamente desde el objeto 'issue'
    fecha_inicio = pd.to_datetime(issue.fields.created)
    fecha_fin = pd.to_datetime(issue.fields.customfield_10077)

    # Genera un rango de fechas diarias entre las fechas de inicio y finalización
    rango_fechas = pd.date_range(start=fecha_inicio, end=fecha_fin)

    # Define una función para verificar si un día es laborable (lunes a viernes)
    def es_dia_laborable(fecha):
        return fecha.weekday() < 5  # 0 corresponde a lunes, 1 a martes, y así sucesivamente

    # Filtra las fechas para obtener solo los días laborables
    dias_laborables = [fecha for fecha in rango_fechas if es_dia_laborable(fecha)]

    # Calcula la cantidad de días laborables
    cantidad_dias_laborables = len(dias_laborables)
    dias_lab.append(cantidad_dias_laborables)

print(len(dias_lab))
print(dias_lab)

"""##Armado del Dataframe"""

# Creamos DF
a={'Proyecto':incidencias_proyecto,'N°_incidencia':incidencias_key,'Responsable':asignados,'SP':points,'Prioridad':incidencias_prioridad,'Tipo_incidencia':incidencias_tipo,'Estado':incidencias_estado,'Costo':presupuesto,'Inicio':incidencias_tiempo_resol,'Cierre':incidencias_tiempo_cierre,'Dias_Laborales':dias_lab}
df=pd.DataFrame(a, index=list(range(1,len(incidencias_proyecto)+1)))

df

'''
# Guardamos DF en un csv o excel
nombre_file=f"df_jira.xlsx"

df.to_excel(nombre_file,index=False)

# PARA DESCARGAR EL ARCHIVO GENERADO
from google.colab import files
files.download(nombre_file)
'''

"""#Data Understanding / Exploratory Data Analysis (EDA)

##Medias de resumen (var num)
"""

#Dimension del DF (filas x col)
print(df.shape)

#Resumen estadístico
df.describe(include='all')

"""### Variables numéricas y categóricas"""

# Obtener la cantidad de variables numéricas y categóricas
num_vars = len(df.select_dtypes(include=['float', 'int']).columns)
cat_vars = len(df.select_dtypes(include=['object', 'category']).columns)

# Imprimir la cantidad de variables numéricas y categóricas
print('Cantidad de variables numéricas:', num_vars)
print('Cantidad de variables categóricas:', cat_vars)

# Lista de Variables y sus tipos
df.dtypes

"""Vamos a transformar a datetime las variables de inicio y fin"""

df['Inicio'] = pd.to_datetime(df['Inicio'],format='%d-%m-%Y %H:%M')

df['Cierre'] = pd.to_datetime(df['Cierre'], errors='coerce')

# Reemplazamos los valores 0 por NaT
df['Cierre'].replace(0, np.nan, inplace=True)

"""Validamos la correcta transformacion"""

df.dtypes

"""###Datos atípicos o outliers"""

# Crear un nuevo dataframe utilizando las variables seleccionadas
df_nuevo = df[['SP','Dias_Laborales']].copy()

# Definir una función para calcular el porcentaje de valores atípicos
def porcentaje_atipicos(columna):
    Q1 = columna.quantile(0.25)
    Q3 = columna.quantile(0.75)
    IQR = Q3 - Q1
    atipicos = ((columna < (Q1 - 1.5 * IQR)) | (columna > (Q3 + 1.5 * IQR))).sum()
    porcentaje = (atipicos / len(columna)) * 100
    return porcentaje

# Calcular el porcentaje de valores atípicos para cada variable
for columna in df_nuevo.columns:
    porcentaje = porcentaje_atipicos(df_nuevo[columna])
    print(f"Variable {columna}: {porcentaje}% de valores atípicos")

"""Podemos considerar tolerable el % de outliers (??)

###Datos faltantes / Valores perdidos
"""

df.info()

# Verificar valores nulos en el DataFrame
valores_nulos = df.isnull()

# Contar valores nulos por columna
valores_nulos_por_columna = valores_nulos.sum()

# Contar valores nulos en total
total_valores_nulos = valores_nulos.sum().sum()

# Imprimir los resultados
print("Valores nulos por columna:")
print(valores_nulos_por_columna)
print("\nTotal de valores nulos:", total_valores_nulos)

missing = df.isnull()

# calcular correlación entre variables con valores no faltantes
corr_matrix = df[~missing].corr(method='pearson')

# mostrar matriz de correlación
print(corr_matrix)

"""No hay correlacion entre variables con valores no faltantes

#Data Preparation / Cleaning / Feature Engineering

Acá la clave es definir el problema a resolver!

Recordar incorporar la metricas tipicas de los proyectos:

En definitiva, se trata de
1. Monitor estado actual
- Total de proyectos
-Total de tareas
-Estado de las tareas
-User workload
-Issue by type
-Presupuesto
-Progreso


2. Modelos predictivos
- Identificar las tareas que tardan más tiempo en completarse.
-Identificar los cuellos de botella en los proyectos.
-Identificar los usuarios que tienen dificultades para completar las tareas.
-Identificar las tareas que son más propensas a errores.

##Monitor Estado Actual de Proyectos

### User workload
"""

workload = pd.crosstab(df['Proyecto'], df['Responsable'])

print(workload)

"""### Issue by type"""

issue__type = pd.crosstab(df['Proyecto'], df['Tipo_incidencia'])

print(issue__type)

"""### Budget"""

# Agrupamos el DataFrame por proyecto.
df_agrupado = df.groupby("Proyecto")

# Calculamos el costo total de cada proyecto.
costo_total = df_agrupado["Costo"].sum()

# Creamos un nuevo DataFrame con el costo total de cada proyecto.
df_costo_total = pd.DataFrame({
        "Proyecto": costo_total.index,
        "Costo total": costo_total.values
    })

print(df_costo_total)

"""### Progress -- Issues Not Done"""

def tareas_no_listas(estados):

  return len([estado for estado in estados if estado != "Listo"])


estados = df['Estado']

tareas_no_listas = tareas_no_listas(estados)

print(tareas_no_listas)

